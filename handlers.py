""
handlers.py â€” MUGON.CLUB HR Bot
Full interview pipeline: verification, GPT dialogue, AmoCRM sync, notifications.
"""
import os
import logging
from aiogram import Router, F, Bot
from aiogram.types import (
    Message, CallbackQuery, ReplyKeyboardMarkup, KeyboardButton,
    InlineKeyboardMarkup, InlineKeyboardButton, ReplyKeyboardRemove,
    KeyboardButtonRequestContact
)
from aiogram.filters import CommandStart, Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup

from gpt import ask_hr_gpt, generate_ai_resume
from amocrm import AmoCRM
from notifier import notify_ceo_pm

logger = logging.getLogger(__name__)
router = Router()

amo = AmoCRM(
    domain=os.environ["AMO_DOMAIN"],
    client_id=os.environ["AMO_CLIENT_ID"],
    client_secret=os.environ["AMO_CLIENT_SECRET"],
    redirect_uri=os.environ["AMO_REDIRECT_URI"],
    refresh_token=os.environ["AMO_REFRESH_TOKEN"],
)

CEO_TG_ID = int(os.environ.get("CEO_TG_ID", "0"))
PM_TG_ID = int(os.environ.get("PM_TG_ID", "0"))
PIPELINE_ID = int(os.environ.get("AMO_PIPELINE_ID", "10599910"))
STATUS_NEW = int(os.environ.get("AMO_STATUS_NEW", "83583878"))


# â”€â”€â”€ FSM States â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class Interview(StatesGroup):
    waiting_contact = State()
    phone_verified = State()
    interviewing = State()
    waiting_resume_file = State()
    completed = State()


# â”€â”€â”€ Keyboards â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main_menu() -> ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(
        keyboard=[
            [KeyboardButton(text="ğŸ“‹ ĞŸÑ€Ğ¾Ğ¹Ñ‚Ğ¸ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ")],
            [KeyboardButton(text="ğŸ—‚ ĞĞ°ÑˆĞ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹"), KeyboardButton(text="ğŸ“„ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑĞ¼Ğµ")],
            [KeyboardButton(text="ğŸ“ ĞŸĞ¾Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ¾Ğ¼", request_contact=True)],
            [KeyboardButton(text="â“ FAQ"), KeyboardButton(text="ğŸ“¬ Ğ¡Ğ²ÑĞ·Ğ°Ñ‚ÑŒÑÑ Ñ HR")],
        ],
        resize_keyboard=True,
        one_time_keyboard=False,
    )


def share_contact_kb() -> ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(
        keyboard=[[KeyboardButton(text="ğŸ“± ĞŸĞ¾Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ¾Ğ¼ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ğ°", request_contact=True)]],
        resize_keyboard=True,
        one_time_keyboard=True,
    )


def projects_inline() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ğŸ¤– AutoHire â€” AI Ñ€ĞµĞºÑ€ÑƒÑ‚Ğ¸Ğ½Ğ³", callback_data="project_autohire")],
        [InlineKeyboardButton(text="ğŸ“Š DataFlow â€” ETL Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°", callback_data="project_dataflow")],
        [InlineKeyboardButton(text="ğŸš€ Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹", callback_data="project_other")],
        [InlineKeyboardButton(text="âœ… Ğ¥Ğ¾Ñ‡Ñƒ ÑƒÑ‡Ğ°ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ!", callback_data="project_apply")],
    ])


# â”€â”€â”€ /start â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.message(CommandStart())
async def cmd_start(message: Message, state: FSMContext):
    await state.clear()
    name = message.from_user.first_name or "ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚"
    await message.answer(
        f"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {name}! ğŸ‘‹\n\n"
        "Ğ¯ â€” HR-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ MUGON.CLUB. ĞœÑ‹ ÑÑ‚Ñ€Ğ¾Ğ¸Ğ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ AI-Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ².\n\n"
        "Ğ§Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ â€” Ğ¿Ğ¾Ğ´ĞµĞ»Ğ¸Ñ‚ĞµÑÑŒ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ¾Ğ¼ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ğ°. Ğ­Ñ‚Ğ¾ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ´Ğ»Ñ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸.\n"
        "ĞŸĞ¾ÑĞ»Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµĞ´Ñƒ Ğ²Ğ°Ñ Ñ‡ĞµÑ€ĞµĞ· ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğµ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ.",
        reply_markup=share_contact_kb(),
    )
    await state.set_state(Interview.waiting_contact)


# â”€â”€â”€ Contact / Phone Verification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.message(Interview.waiting_contact, F.contact)
async def got_contact(message: Message, state: FSMContext, bot: Bot):
    contact = message.contact
    phone = contact.phone_number
    user = message.from_user

    await state.update_data(
        phone=phone,
        tg_id=user.id,
        username=user.username or "",
        full_name=f"{user.first_name or ''} {user.last_name or ''}".strip(),
    )
    await state.set_state(Interview.phone_verified)

    # Create/find lead in AmoCRM
    lead_id = await amo.find_or_create_lead(
        name=f"{user.first_name or 'ĞšĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚'} @{user.username or user.id}",
        phone=phone,
        tg_id=str(user.id),
        pipeline_id=PIPELINE_ID,
        status_id=STATUS_NEW,
    )
    await state.update_data(lead_id=lead_id)

    await message.answer(
        f"âœ… ĞĞ¾Ğ¼ĞµÑ€ {phone} Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´Ñ‘Ğ½!\n\n"
        "ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾, Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ½Ğ°Ñ‡Ğ½Ñ‘Ğ¼ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ. Ğ¯ Ğ·Ğ°Ğ´Ğ°Ğ¼ Ğ²Ğ°Ğ¼ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ².\n"
        "ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹Ñ‚Ğµ ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾ â€” ÑÑ‚Ğ¾ Ğ¶Ğ¸Ğ²Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³, Ğ½Ğµ Ñ‚ĞµÑÑ‚ Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ğ¼Ğ¸.\n\n"
        "Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹? Ğ¢Ğ¾Ğ³Ğ´Ğ° Ğ½Ğ°Ñ‡Ğ½Ñ‘Ğ¼ ğŸš€",
        reply_markup=ReplyKeyboardRemove(),
    )
    await state.set_state(Interview.interviewing)

    # Initialize dialogue history and ask first question
    await state.update_data(history=[], questions_asked=0, scores={})
    first_q = await ask_hr_gpt([], "START_INTERVIEW", user_name=user.first_name)
    await message.answer(first_q)


@router.message(Interview.waiting_contact)
async def request_contact_again(message: Message):
    await message.answer(
        "Ğ”Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ¿Ğ¾Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ¾Ğ¼ĞµÑ€Ğ¾Ğ¼ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ğ°.\n"
        "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ Ğ½Ğ¸Ğ¶Ğµ ğŸ‘‡",
        reply_markup=share_contact_kb(),
    )


# â”€â”€â”€ Main Interview Flow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.message(Interview.interviewing, F.text)
async def interview_message(message: Message, state: FSMContext, bot: Bot):
    data = await state.get_data()
    history = data.get("history", [])
    questions_asked = data.get("questions_asked", 0)
    lead_id = data.get("lead_id")
    user_name = message.from_user.first_name

    # Add user message to history
    history.append({"role": "user", "content": message.text})

    # Check if interview should end (30 questions max or GPT decides)
    if questions_asked >= 30:
        await finalize_interview(message, state, bot, history, lead_id, user_name)
        return

    # Get next GPT response
    gpt_reply = await ask_hr_gpt(history, "CONTINUE", user_name=user_name)
    history.append({"role": "assistant", "content": gpt_reply})

    await state.update_data(history=history, questions_asked=questions_asked + 1)
    await message.answer(gpt_reply)

    # Check if GPT signals end of interview
    if "INTERVIEW_COMPLETE" in gpt_reply or questions_asked >= 28:
        await finalize_interview(message, state, bot, history, lead_id, user_name)


@router.message(Interview.interviewing, F.document | F.photo)
async def interview_resume_file(message: Message, state: FSMContext, bot: Bot):
    """Handle resume file upload during interview."""
    data = await state.get_data()
    lead_id = data.get("lead_id")

    # Download and process resume
    if message.document:
        file_id = message.document.file_id
        file_name = message.document.file_name or "resume.pdf"
    elif message.photo:
        file_id = message.photo[-1].file_id
        file_name = "resume_photo.jpg"
    else:
        return

    file = await bot.get_file(file_id)
    file_bytes = await bot.download_file(file.file_path)

    # Upload to AmoCRM
    if lead_id:
        await amo.upload_resume_file(lead_id, file_bytes, file_name)

    await message.answer(
        "ğŸ“ Ğ ĞµĞ·ÑĞ¼Ğµ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¾ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ Ğ² Ğ²Ğ°ÑˆĞµĞ¹ ĞºĞ°Ñ€Ñ‚Ğ¾Ñ‡ĞºĞµ!\n"
        "Ğ¯ ĞµĞ³Ğ¾ Ğ¸Ğ·ÑƒÑ‡Ñƒ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ğ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°ÑÑ‰Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹. ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ ğŸ‘‡"
    )

    # Continue interview with context that resume was received
    data = await state.get_data()
    history = data.get("history", [])
    history.append({"role": "user", "content": f"[ĞšĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚ Ğ¿Ñ€Ğ¸ÑĞ»Ğ°Ğ» Ñ€ĞµĞ·ÑĞ¼Ğµ: {file_name}]"})
    gpt_reply = await ask_hr_gpt(history, "RESUME_RECEIVED", user_name=message.from_user.first_name)
    history.append({"role": "assistant", "content": gpt_reply})
    await state.update_data(history=history)
    await message.answer(gpt_reply)


async def finalize_interview(message: Message, state: FSMContext, bot: Bot, history: list, lead_id: int, user_name: str):
    """Finalize interview: generate AI resume, update AmoCRM, notify CEO/PM."""
    await message.answer(
        "ğŸ ĞœÑ‹ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ğ»Ğ¸ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½ÑƒÑ Ñ‡Ğ°ÑÑ‚ÑŒ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ!\n"
        "Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒÑ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ñ€ĞµĞ·ÑĞ¼Ğµ Ğ¸ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğµ. Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ğ¹Ğ¼Ñ‘Ñ‚ Ğ¿Ğ°Ñ€Ñƒ ÑĞµĞºÑƒĞ½Ğ´..."
    )

    data = await state.get_data()

    # Generate AI resume and scores
    ai_resume = await generate_ai_resume(history, user_name)

    # Update AmoCRM fields
    if lead_id:
        await amo.update_lead_fields(lead_id, ai_resume)

    # Notify CEO and PM
    await notify_ceo_pm(bot, CEO_TG_ID, PM_TG_ID, data, ai_resume)

    await state.set_state(Interview.completed)
    await message.answer(
        "âœ… ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾! Ğ’Ğ°ÑˆĞµ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾.\n\n"
        f"Ğ’Ğ°Ñˆ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ±Ğ°Ğ»Ğ»: *{ai_resume.get('total_score', 'â€”')}/100*\n\n"
        "ĞĞ°ÑˆĞ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ñ‚ Ğ²Ğ°ÑˆÑƒ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚ÑƒÑ€Ñƒ Ğ¸ ÑĞ²ÑĞ¶ĞµÑ‚ÑÑ Ñ Ğ²Ğ°Ğ¼Ğ¸ Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ 2-3 Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ñ… Ğ´Ğ½ĞµĞ¹.\n\n"
        "Ğ¥Ğ¾Ñ‚Ğ¸Ñ‚Ğµ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¾ Ğ½Ğ°ÑˆĞ¸Ñ… Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ñ…?",
        reply_markup=projects_inline(),
        parse_mode="Markdown",
    )


# â”€â”€â”€ Project Info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.callback_query(F.data.startswith("project_"))
async def project_info(callback: CallbackQuery):
    projects = {
        "project_autohire": (
            "ğŸ¤– *AutoHire â€” AI Recruitment Platform*\n\n"
            "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğ°Ğ¹Ğ¼Ğ° Ñ‡ĞµÑ€ĞµĞ· AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²: Ğ¾Ñ‚ Ğ¸Ğ´ĞµĞ¸ Ğ´Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚Ğ°.\n"
            "Ğ¡Ñ‚ĞµĞº: Python, FastAPI, Telegram, GPT-4, AmoCRM.\n"
            "Ğ˜Ñ‰ĞµĞ¼: Python Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ², AI-Ğ¸Ğ½Ğ¶ĞµĞ½ĞµÑ€Ğ¾Ğ², PM."
        ),
        "project_dataflow": (
            "ğŸ“Š *DataFlow â€” ETL & Analytics Platform*\n\n"
            "Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ´Ğ°ÑˆĞ±Ğ¾Ñ€Ğ´Ğ°Ğ¼Ğ¸.\n"
            "Ğ¡Ñ‚ĞµĞº: Python, Celery, PostgreSQL, Redis, React.\n"
            "Ğ˜Ñ‰ĞµĞ¼: Backend Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ², Data Engineers."
        ),
        "project_other": (
            "ğŸš€ *Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹ MUGON.CLUB*\n\n"
            "Ğ£ Ğ½Ğ°Ñ ĞµÑÑ‚ÑŒ Ñ€ÑĞ´ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ¾Ğ² Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ AI, Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸.\n"
            "ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ â€” Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ´ĞµÑ Ñ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»Ğ¾Ğ¼ Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.\n"
            "Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ."
        ),
        "project_apply": None,
    }

    if callback.data == "project_apply":
        await callback.message.answer(
            "ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾! ĞŸÑ€Ğ¾Ğ¹Ğ´Ğ¸Ñ‚Ğµ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¼Ñ‹ Ğ¿Ğ¾Ğ´Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ¿Ğ¾Ğ´ Ğ²Ğ°Ñˆ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ.\n"
            "ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ /start Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ."
        )
    else:
        text = projects.get(callback.data, "Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°")
        await callback.message.answer(text, parse_mode="Markdown")

    await callback.answer()


# â”€â”€â”€ Menu Buttons â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.message(F.text == "ğŸ“‹ ĞŸÑ€Ğ¾Ğ¹Ñ‚Ğ¸ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ")
async def start_interview_btn(message: Message, state: FSMContext):
    await cmd_start(message, state)


@router.message(F.text == "ğŸ—‚ ĞĞ°ÑˆĞ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹")
async def show_projects(message: Message):
    await message.answer(
        "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸:",
        reply_markup=projects_inline(),
    )


@router.message(F.text == "â“ FAQ")
async def faq(message: Message):
    await message.answer(
        "*Ğ§Ğ°ÑÑ‚Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹*\n\n"
        "â“ *Ğ§Ñ‚Ğ¾ Ñ‚Ğ°ĞºĞ¾Ğµ MUGON.CLUB?*\n"
        "ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»Ğ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµÑ‚ AI-Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹ Ğ¾Ñ‚ Ğ¸Ğ´ĞµĞ¸ Ğ´Ğ¾ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°.\n\n"
        "â“ *ĞšĞ°ĞºĞ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹?*\n"
        "Full-time, part-time Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ½Ğ°Ñ Ğ·Ğ°Ğ½ÑÑ‚Ğ¾ÑÑ‚ÑŒ. Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾.\n\n"
        "â“ *ĞÑƒĞ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ¿Ğ»Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ·Ğ° ÑƒÑ‡Ğ°ÑÑ‚Ğ¸Ğµ?*\n"
        "ĞĞµÑ‚. ĞœÑ‹ Ğ¿Ğ»Ğ°Ñ‚Ğ¸Ğ¼ Ğ·Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚.\n\n"
        "â“ *ĞšĞ°Ğº Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¾Ñ‚Ğ±Ğ¾Ñ€?*\n"
        "1. Ğ¡Ğ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Ğ±Ğ¾Ñ‚Ğµ\n2. Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ\n3. ĞĞ½Ğ±Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ³ Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚\n\n"
        "â“ *Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ğ¸Ñ‚ÑÑ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ?*\n"
        "15-20 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°.",
        parse_mode="Markdown",
    )


@router.message(F.text == "ğŸ“„ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑĞ¼Ğµ")
async def request_resume(message: Message, state: FSMContext):
    data = await state.get_data()
    if not data.get("lead_id"):
        await message.answer("Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ¹Ñ‚Ğ¸ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ. ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ /start")
        return
    await state.set_state(Interview.waiting_resume_file)
    await message.answer(
        "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ÑŒÑ‚Ğµ Ñ„Ğ°Ğ¹Ğ» Ñ€ĞµĞ·ÑĞ¼Ğµ (PDF, DOCX Ğ¸Ğ»Ğ¸ Ñ„Ğ¾Ñ‚Ğ¾). "
        "Ğ¯ Ğ¸Ğ·ÑƒÑ‡Ñƒ ĞµĞ³Ğ¾ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ğ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°ÑÑ‰Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹.",
        reply_markup=ReplyKeyboardRemove(),
    )


@router.message(F.text == "ğŸ“¬ Ğ¡Ğ²ÑĞ·Ğ°Ñ‚ÑŒÑÑ Ñ HR")
async def contact_hr(message: Message):
    await message.answer(
        "Ğ’Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ ÑĞ²ÑĞ·Ğ°Ñ‚ÑŒÑÑ Ñ HR Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ:\n"
        "ğŸ“§ hr@mugon.club\n"
        "Ğ˜Ğ»Ğ¸ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ ÑĞ²Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ, Ğ¸ Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ¼ ĞµĞ³Ğ¾ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğµ."
    )


# â”€â”€â”€ Group: New member greeting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.message(F.new_chat_members)
async def new_member(message: Message):
    for member in message.new_chat_members:
        if not member.is_bot:
            await message.answer(
                f"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {member.first_name}! ğŸ‘‹ Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² MUGON.CLUB!\n\n"
                f"ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑˆĞ¸Ñ‚ĞµÑÑŒ Ğ½Ğ° Ğ½Ğ°ÑˆĞµĞ³Ğ¾ HR-Ğ±Ğ¾Ñ‚Ğ° @MUGON_CLUB_BOT â€” Ñ‚Ğ°Ğ¼ Ğ²Ñ‹ ÑĞ¼Ğ¾Ğ¶ĞµÑ‚Ğµ:\n"
                f"â€¢ ĞŸÑ€Ğ¾Ğ¹Ñ‚Ğ¸ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ\n"
                f"â€¢ Ğ£Ğ·Ğ½Ğ°Ñ‚ÑŒ Ğ¾ Ğ½Ğ°ÑˆĞ¸Ñ… Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ñ…\n"
                f"â€¢ ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ\n\n"
                f"ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ: @MUGON_CLUB_BOT"
            )


# â”€â”€â”€ Re-engagement: remind non-responding candidates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.message(Interview.interviewing, F.text.in_({"ÑÑ‚Ğ¾Ğ¿", "Ğ¿Ğ°ÑƒĞ·Ğ°", "Ğ¿Ğ¾Ğ·Ğ¶Ğµ", "Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼"}))
async def pause_interview(message: Message, state: FSMContext):
    await message.answer(
        "Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¾, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ²Ğ°Ñˆ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ. ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ¼Ğ½Ğµ ĞºĞ¾Ğ³Ğ´Ğ° Ğ±ÑƒĞ´ĞµÑ‚Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ.\n"
        "Ğ¯ Ğ½Ğ°Ğ¿Ğ¾Ğ¼Ğ½Ñ Ğ¾ ÑĞµĞ±Ğµ Ñ‡ĞµÑ€ĞµĞ· 24 Ñ‡Ğ°ÑĞ° ğŸ˜Š"
    )


@router.message(Interview.completed)
async def completed_state(message: Message):
    await message.answer(
        "Ğ’Ñ‹ ÑƒĞ¶Ğµ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¸ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ. ĞĞ°ÑˆĞ° ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° ÑĞºĞ¾Ñ€Ğ¾ ÑĞ²ÑĞ¶ĞµÑ‚ÑÑ Ñ Ğ²Ğ°Ğ¼Ğ¸!\n"
        "Ğ•ÑĞ»Ğ¸ Ñ…Ğ¾Ñ‚Ğ¸Ñ‚Ğµ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ñ… â€” Ğ½Ğ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ 'ğŸ—‚ ĞĞ°ÑˆĞ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñ‹'",
        reply_markup=main_menu(),
    )
